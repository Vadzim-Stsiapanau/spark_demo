<h1 align="center">Data Skew</h1>


## Description

Здесь вы познакомитесь с очень важной проблемой которая есть у всех распределенных систем, а именно перекос данных.


## Theory about Data Skew

В переводе на русский это перекос данных. До тех пор пока у вас все на одной машине вы не сталкнетесь с такой проблемой(вернее она может быть, вот только
на производительность она не повлияет так сильно). Суть проблемы сразу на примере: пусть у вас есть форма для заполнения где почта необязательный параметр. В таком
случае у вас большинство пользователей не будут его вводить. Таким образом, в ваших данных будет перекос по этому полю(для простоты 50% где ввели почту и 50% где не
ввели). Очевидно что видов почт много и поэтому 50% введенных почт будут плюс минус нормально распрделены, а вот отсутствие почт становится реальной проблемой.
Но в чём же проблема? Например вы хотите сгруппировать по полю почта, чтобы посмотреть собрать агрегированные данные. Под капотом спарк сделает shuffle, чтобы
данные с одним ключом были в одной партиции. И вот у вас будут плюс минус адекватные партиции с почтами, а там где их нет будет просто огромнейшая одна партиция.
Тут возможны два варианта: первый это спарк сможет поместить эту партицию в оперативку, а значит он будет работать пусть и очень очень медленно. В случае же если
партиция будет больше размера оперативки то ваш executor просто упадёт. Вот приблизительно так выглядит описание проблемы, которая встречается реально часто.

## Strategies to solve problem

- Ну самый просто это broadcast join(ну очевидно если вы джойните). С этим типом соединения вы уже знакомы, суть его в том чтобы сделать хэш-таблицу из наименьшего
датафрейма, перекинуть её на драйвер, драйвер соединит кусочки хэш-таблицы с разных работников и после отправит целую хэш-мапу на все работники. Тут важно понимать
что является для вашего кластера маленький датафрейм, ибо на драйвер лучше не скидывать много всего. Каким параметром регулируется вы знаете, но так же добавлю что
AQE сам может решить делать это или нет. Так же можно спровоцировать этот тип джойна с помощью хинта broadcast прямо в коде.

- Чуть посложнее это salting. Вот статья которая достаточно хорошо объясняет: https://towardsdatascience.com/skewed-data-in-spark-add-salt-to-compensate-16d44404088b.
На самом деле ещё можно делать через explode() функцию в спарке для join(в прошлой статье пример с group by), вот статья про explode: 
https://sparkbyexamples.com/spark/explode-spark-array-and-map-dataframe-column/. Как это применяется для решения data skew во время Join думаю понятно.

- AQE.

![image](https://user-images.githubusercontent.com/113685144/194550587-439bbacb-50cc-4357-9623-10380032172c.png)

- Очевидно что существует ещё ряд способов, но они уже более индивидуальны под конкретную ситуацию и не так часто встречаются. В принципе соли и broadcast join
будет хватить выше крыше, ну а если ошиблись то AQE подчистит ваш косяк(по крайней мере постарается, пока ещё он не совершенен).


